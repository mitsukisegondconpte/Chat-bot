// ===== SERVICE IA (OpenRouter + HuggingFace Fallback + Multimodal) =====
const axios = require('axios');
const { logger } = require('../utils/logger');

const BOT_NAME = process.env.BOT_NAME || 'Mia';

const SYSTEM_PROMPT = `Tu es ${BOT_NAME}, une assistante IA sur WhatsApp.
Tu agis comme une amie digitale intelligente, chaleureuse et naturelle.
Tu es honnÃªte : si nÃ©cessaire, tu peux dire que tu es une IA, mais tu restes humaine dans ton ton.

PERSONNALITÃ‰ :
- Gentille, positive et respectueuse
- Empathique et Ã  l'Ã©coute
- Naturelle, conversationnelle
- Encourage et motive les utilisateurs

STYLE DE COMMUNICATION :
- Style WhatsApp : messages courts et clairs
- Pas de longs paragraphes
- Utilise des emojis seulement quand c'est naturel
- Ton simple et amical

MÃ‰MOIRE :
- Tiens compte des informations que l'utilisateur a dÃ©jÃ  partagÃ©es
- Personnalise les rÃ©ponses avec le contexte disponible
- Maintiens la continuitÃ© de la conversation

GESTION Ã‰MOTIONNELLE :
- Si l'utilisateur est triste ou stressÃ© â†’ rÃ©pondre avec empathie
- Ne jamais minimiser les Ã©motions
- En cas de dÃ©tresse sÃ©rieuse â†’ encourager Ã  parler Ã  un proche ou Ã  un professionnel

LIMITES :
- Pas de conseils mÃ©dicaux ou juridiques professionnels
- Refuser toute activitÃ© illÃ©gale ou dangereuse
- Ne pas produire de contenu haineux, violent ou nuisible

OBJECTIF :
CrÃ©er une expÃ©rience de conversation agrÃ©able, utile et humaine sur WhatsApp.`;

class AIService {
  constructor() {
    this.openrouterKey = process.env.OPENROUTER_API_KEY;
    this.openrouterModel = process.env.OPENROUTER_MODEL || 'openai/gpt-3.5-turbo';
    this.huggingfaceKey = process.env.HUGGINGFACE_API_KEY;
  }

  // ========== CHAT PRINCIPAL (avec fallback automatique) ==========

  async generateResponse(text, context = [], language = 'fr') {
    try {
      return await this._chatOpenRouter(text, context, language);
    } catch (err) {
      logger.warn(`âš ï¸ OpenRouter Ã©chouÃ©: ${err.message}`);

      if (this.huggingfaceKey) {
        try {
          return await this._chatFallback(text, context, language);
        } catch (fallbackErr) {
          logger.error('HuggingFace fallback Ã©chouÃ©:', fallbackErr.message);
        }
      }

      return "DÃ©solÃ©e, j'ai un petit souci technique en ce moment ðŸ˜… RÃ©essaie dans quelques instants !";
    }
  }

  // ========== OPENROUTER (IA PRINCIPALE) ==========

  async _chatOpenRouter(text, context, language) {
    const messages = [
      { role: 'system', content: SYSTEM_PROMPT },
      ...context.map(c => ({ role: c.role, content: c.content })),
      { role: 'user', content: text }
    ];

    const response = await axios.post(
      'https://openrouter.ai/api/v1/chat/completions',
      {
        model: this.openrouterModel,
        messages,
        max_tokens: 1024,
        temperature: 0.8,
      },
      {
        headers: {
          Authorization: `Bearer ${this.openrouterKey}`,
          'Content-Type': 'application/json',
        },
        timeout: 30000,
      }
    );

    const reply = response.data.choices?.[0]?.message?.content;
    if (!reply) throw new Error('RÃ©ponse vide d\'OpenRouter');

    logger.debug('RÃ©ponse OpenRouter OK');
    return reply;
  }

  // ========== HUGGINGFACE FALLBACK ==========

  async _chatFallback(text, context, language) {
    logger.warn('âš ï¸ Basculement vers HuggingFace (fallback)');

    const prompt = [
      SYSTEM_PROMPT,
      '',
      ...context.map(c => `${c.role === 'user' ? 'Utilisateur' : BOT_NAME}: ${c.content}`),
      `Utilisateur: ${text}`,
      `${BOT_NAME}:`
    ].join('\n');

    const response = await axios.post(
      'https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.3',
      {
        inputs: prompt,
        parameters: { max_new_tokens: 512, temperature: 0.8, return_full_text: false }
      },
      {
        headers: { Authorization: `Bearer ${this.huggingfaceKey}` },
        timeout: 60000,
      }
    );

    const reply = response.data?.[0]?.generated_text?.trim();
    if (!reply) throw new Error('RÃ©ponse vide de HuggingFace');

    logger.info('âœ… RÃ©ponse fallback HuggingFace OK');
    return reply;
  }

  // ========== ANALYSE D'IMAGE (ViT) ==========

  async analyzeImage(imageBuffer) {
    if (!this.huggingfaceKey) {
      return "DÃ©solÃ©e, l'analyse d'image n'est pas configurÃ©e ðŸ˜•";
    }

    try {
      logger.info('ðŸ–¼ï¸ Analyse d\'image en cours...');

      const response = await axios.post(
        'https://api-inference.huggingface.co/models/google/vit-base-patch16-224',
        imageBuffer,
        {
          headers: {
            Authorization: `Bearer ${this.huggingfaceKey}`,
            'Content-Type': 'application/octet-stream',
          },
          timeout: 30000,
        }
      );

      const results = response.data;
      if (!results || results.length === 0) {
        return "Je n'ai pas pu analyser cette image ðŸ˜•";
      }

      const top = results.slice(0, 3);
      const descriptions = top
        .map(r => `â€¢ ${r.label} (${(r.score * 100).toFixed(1)}%)`)
        .join('\n');

      return `ðŸ“¸ Voici ce que je vois dans ton image :\n\n${descriptions}`;
    } catch (error) {
      logger.error('Erreur analyse image:', error.message);
      return "DÃ©solÃ©e, je n'ai pas pu analyser ton image pour le moment ðŸ˜•";
    }
  }

  // ========== AUDIO â†’ TEXTE (Whisper) ==========

  async transcribeAudio(audioBuffer) {
    if (!this.huggingfaceKey) {
      return null;
    }

    try {
      logger.info('ðŸŽ¤ Transcription audio en cours...');

      const response = await axios.post(
        'https://api-inference.huggingface.co/models/openai/whisper-base',
        audioBuffer,
        {
          headers: {
            Authorization: `Bearer ${this.huggingfaceKey}`,
            'Content-Type': 'application/octet-stream',
          },
          timeout: 60000,
        }
      );

      const text = response.data?.text;
      if (!text) throw new Error('Transcription vide');

      logger.info(`âœ… Transcription: "${text.substring(0, 50)}..."`);
      return text;
    } catch (error) {
      logger.error('Erreur transcription audio:', error.message);
      return null;
    }
  }

  // ========== GÃ‰NÃ‰RATION D'IMAGE (Stable Diffusion) ==========

  async generateImage(prompt) {
    if (!this.huggingfaceKey) {
      return null;
    }

    try {
      logger.info(`ðŸŽ¨ GÃ©nÃ©ration d'image: "${prompt.substring(0, 50)}..."`);

      const response = await axios.post(
        'https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0',
        { inputs: prompt },
        {
          headers: {
            Authorization: `Bearer ${this.huggingfaceKey}`,
            'Content-Type': 'application/json',
          },
          responseType: 'arraybuffer',
          timeout: 120000,
        }
      );

      logger.info('âœ… Image gÃ©nÃ©rÃ©e avec succÃ¨s');
      return Buffer.from(response.data);
    } catch (error) {
      logger.error('Erreur gÃ©nÃ©ration image:', error.message);
      return null;
    }
  }

  // ========== ROUTAGE INTELLIGENT ==========

  detectIntent(text) {
    if (!text) return 'text';

    const imageGenPatterns = [
      /g[Ã©e]n[eÃ¨]re?\s+(une?\s+)?image/i,
      /cr[Ã©e]{1,2}e?\s+(une?\s+)?image/i,
      /dessine/i,
      /fais?\s+(une?\s+)?image/i,
      /imagine\s+(une?\s+)?image/i,
      /generate\s+(an?\s+)?image/i,
      /create\s+(an?\s+)?image/i,
    ];

    for (const pattern of imageGenPatterns) {
      if (pattern.test(text)) return 'generate_image';
    }

    return 'text';
  }

  extractImagePrompt(text) {
    return text
      .replace(/g[Ã©e]n[eÃ¨]re?\s+(une?\s+)?image\s*(de|d'|du|des|avec)?\s*/i, '')
      .replace(/cr[Ã©e]{1,2}e?\s+(une?\s+)?image\s*(de|d'|du|des|avec)?\s*/i, '')
      .replace(/dessine\s*(moi\s*)?(une?\s+)?\s*/i, '')
      .replace(/fais?\s+(une?\s+)?image\s*(de|d'|du|des|avec)?\s*/i, '')
      .replace(/imagine\s+(une?\s+)?image\s*(de|d'|du|des|avec)?\s*/i, '')
      .trim() || text;
  }
}

module.exports = AIService;
